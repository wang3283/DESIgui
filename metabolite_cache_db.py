#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»£è°¢ç‰©æ³¨é‡Šç¼“å­˜æ•°æ®åº“
æŒä¹…åŒ–ä¿å­˜æ³¨é‡Šç»“æœï¼Œé¿å…é‡å¤æŸ¥è¯¢
"""

import sqlite3
import json
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime


class MetaboliteCacheDB:
    """ä»£è°¢ç‰©æ³¨é‡Šç¼“å­˜æ•°æ®åº“"""
    
    def __init__(self, db_path: str = None):
        """
        åˆå§‹åŒ–ç¼“å­˜æ•°æ®åº“
        
        å‚æ•°:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º metabolite_cache.db
        """
        if db_path is None:
            db_path = Path(__file__).parent / "metabolite_cache.db"
        
        self.db_path = str(db_path)
        self.conn = None
        self.cursor = None
        
        self._init_database()
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        self.conn = sqlite3.connect(self.db_path)
        self.cursor = self.conn.cursor()
        
        # åˆ›å»ºæ³¨é‡Šç¼“å­˜è¡¨
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS annotation_cache (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                mz REAL NOT NULL,
                tolerance_ppm REAL NOT NULL,
                ion_mode TEXT NOT NULL,
                metabolite_name TEXT,
                formula TEXT,
                hmdb_id TEXT,
                molecular_weight REAL,
                cas_number TEXT,
                kegg_id TEXT,
                kingdom TEXT,
                super_class TEXT,
                class TEXT,
                sub_class TEXT,
                theoretical_mz REAL,
                error_ppm REAL,
                error_da REAL,
                source TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(mz, tolerance_ppm, ion_mode, metabolite_name)
            )
        ''')
        
        # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢é€Ÿåº¦
        self.cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_mz_mode 
            ON annotation_cache(mz, ion_mode)
        ''')
        
        # åˆ›å»ºç»Ÿè®¡ä¿¡æ¯è¡¨
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS cache_stats (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                total_queries INTEGER DEFAULT 0,
                cache_hits INTEGER DEFAULT 0,
                cache_misses INTEGER DEFAULT 0,
                last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
        self.cursor.execute('SELECT COUNT(*) FROM cache_stats')
        if self.cursor.fetchone()[0] == 0:
            self.cursor.execute('''
                INSERT INTO cache_stats (total_queries, cache_hits, cache_misses)
                VALUES (0, 0, 0)
            ''')
        
        self.conn.commit()
        
        print(f"[æˆåŠŸ] ä»£è°¢ç‰©ç¼“å­˜æ•°æ®åº“å·²åˆå§‹åŒ–: {self.db_path}")
    
    def query_cache(self, mz: float, tolerance_ppm: float, 
                   ion_mode: str) -> List[Dict]:
        """
        ä»ç¼“å­˜æŸ¥è¯¢æ³¨é‡Šç»“æœ
        
        å‚æ•°:
            mz: m/zå€¼
            tolerance_ppm: è¯¯å·®å®¹å¿åº¦
            ion_mode: ç¦»å­æ¨¡å¼
        
        è¿”å›:
            åŒ¹é…çš„ä»£è°¢ç‰©åˆ—è¡¨
        """
        # è®¡ç®—æœç´¢èŒƒå›´
        mz_min = mz * (1 - tolerance_ppm / 1e6)
        mz_max = mz * (1 + tolerance_ppm / 1e6)
        
        self.cursor.execute('''
            SELECT metabolite_name, formula, hmdb_id, molecular_weight,
                   cas_number, kegg_id, kingdom, super_class, class, sub_class,
                   theoretical_mz, error_ppm, error_da, source
            FROM annotation_cache
            WHERE ion_mode = ?
              AND theoretical_mz >= ?
              AND theoretical_mz <= ?
            ORDER BY error_ppm
        ''', (ion_mode, mz_min, mz_max))
        
        results = []
        for row in self.cursor.fetchall():
            # é‡æ–°è®¡ç®—å½“å‰m/zçš„è¯¯å·®
            theoretical_mz = row[10]
            error_da = abs(mz - theoretical_mz)
            error_ppm = (error_da / theoretical_mz) * 1e6
            
            if error_ppm <= tolerance_ppm:
                results.append({
                    'name': row[0],
                    'formula': row[1],
                    'hmdb_id': row[2],
                    'molecular_weight': row[3],
                    'cas_number': row[4],
                    'kegg_id': row[5],
                    'kingdom': row[6],
                    'super_class': row[7],
                    'class': row[8],
                    'sub_class': row[9],
                    'theoretical_mz': row[10],
                    'measured_mz': mz,
                    'error_ppm': error_ppm,
                    'error_da': error_da,
                    'source': row[13] + ' (cached)'
                })
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        if results:
            self._update_stats(cache_hit=True)
        else:
            self._update_stats(cache_hit=False)
        
        return results
    
    def add_annotation(self, mz: float, tolerance_ppm: float, 
                      ion_mode: str, annotation: Dict):
        """
        æ·»åŠ æ³¨é‡Šç»“æœåˆ°ç¼“å­˜
        
        å‚æ•°:
            mz: m/zå€¼
            tolerance_ppm: è¯¯å·®å®¹å¿åº¦
            ion_mode: ç¦»å­æ¨¡å¼
            annotation: æ³¨é‡Šç»“æœå­—å…¸
        """
        try:
            self.cursor.execute('''
                INSERT OR REPLACE INTO annotation_cache
                (mz, tolerance_ppm, ion_mode, metabolite_name, formula,
                 hmdb_id, molecular_weight, cas_number, kegg_id,
                 kingdom, super_class, class, sub_class,
                 theoretical_mz, error_ppm, error_da, source)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                mz,
                tolerance_ppm,
                ion_mode,
                annotation.get('name', ''),
                annotation.get('formula', ''),
                annotation.get('hmdb_id', ''),
                annotation.get('molecular_weight', 0),
                annotation.get('cas_number', ''),
                annotation.get('kegg_id', ''),
                annotation.get('kingdom', ''),
                annotation.get('super_class', ''),
                annotation.get('class', ''),
                annotation.get('sub_class', ''),
                annotation.get('theoretical_mz', 0),
                annotation.get('error_ppm', 0),
                annotation.get('error_da', 0),
                annotation.get('source', 'Unknown')
            ))
            
            self.conn.commit()
        except sqlite3.IntegrityError:
            # å¦‚æœå·²å­˜åœ¨ç›¸åŒè®°å½•ï¼Œå¿½ç•¥
            pass
    
    def batch_add_annotations(self, annotations: List[tuple]):
        """
        æ‰¹é‡æ·»åŠ æ³¨é‡Šç»“æœ
        
        å‚æ•°:
            annotations: [(mz, tolerance_ppm, ion_mode, annotation_dict), ...]
        """
        for mz, tolerance_ppm, ion_mode, annotation in annotations:
            self.add_annotation(mz, tolerance_ppm, ion_mode, annotation)
    
    def _update_stats(self, cache_hit: bool = True):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        if cache_hit:
            self.cursor.execute('''
                UPDATE cache_stats
                SET total_queries = total_queries + 1,
                    cache_hits = cache_hits + 1,
                    last_updated = CURRENT_TIMESTAMP
                WHERE id = 1
            ''')
        else:
            self.cursor.execute('''
                UPDATE cache_stats
                SET total_queries = total_queries + 1,
                    cache_misses = cache_misses + 1,
                    last_updated = CURRENT_TIMESTAMP
                WHERE id = 1
            ''')
        self.conn.commit()
    
    def get_stats(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        self.cursor.execute('''
            SELECT total_queries, cache_hits, cache_misses, last_updated
            FROM cache_stats
            WHERE id = 1
        ''')
        
        row = self.cursor.fetchone()
        if row:
            total, hits, misses, updated = row
            hit_rate = (hits / total * 100) if total > 0 else 0
            
            return {
                'total_queries': total,
                'cache_hits': hits,
                'cache_misses': misses,
                'hit_rate': hit_rate,
                'last_updated': updated,
                'total_cached_annotations': self._get_total_annotations()
            }
        
        return {}
    
    def _get_total_annotations(self) -> int:
        """è·å–ç¼“å­˜ä¸­çš„æ€»æ³¨é‡Šæ•°"""
        self.cursor.execute('SELECT COUNT(*) FROM annotation_cache')
        return self.cursor.fetchone()[0]
    
    def export_cache_to_csv(self, output_file: str):
        """å¯¼å‡ºç¼“å­˜æ•°æ®ä¸ºCSVæ–‡ä»¶"""
        import pandas as pd
        
        self.cursor.execute('''
            SELECT mz, ion_mode, metabolite_name, formula, hmdb_id,
                   theoretical_mz, error_ppm, source, created_at
            FROM annotation_cache
            ORDER BY ion_mode, mz
        ''')
        
        rows = self.cursor.fetchall()
        columns = ['mz', 'ion_mode', 'metabolite_name', 'formula', 'hmdb_id',
                  'theoretical_mz', 'error_ppm', 'source', 'created_at']
        
        df = pd.DataFrame(rows, columns=columns)
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        print(f"[æˆåŠŸ] ç¼“å­˜æ•°æ®å·²å¯¼å‡ºåˆ°: {output_file}")
        print(f"   æ€»è®°å½•æ•°: {len(df)}")
    
    def import_cache_from_csv(self, csv_file: str):
        """ä»CSVæ–‡ä»¶å¯¼å…¥ç¼“å­˜æ•°æ®"""
        import pandas as pd
        
        df = pd.read_csv(csv_file)
        
        count = 0
        for _, row in df.iterrows():
            try:
                self.cursor.execute('''
                    INSERT OR REPLACE INTO annotation_cache
                    (mz, tolerance_ppm, ion_mode, metabolite_name, formula,
                     hmdb_id, theoretical_mz, error_ppm, error_da, source)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    row['mz'],
                    10.0,  # é»˜è®¤å®¹å¿åº¦
                    row['ion_mode'],
                    row['metabolite_name'],
                    row['formula'],
                    row['hmdb_id'],
                    row['theoretical_mz'],
                    row['error_ppm'],
                    0.0,  # error_daå¯ä»å…¶ä»–åˆ—è®¡ç®—
                    row['source']
                ))
                count += 1
            except Exception as e:
                print(f"[è­¦å‘Š] å¯¼å…¥å¤±è´¥ (è¡Œ{count}): {e}")
        
        self.conn.commit()
        print(f"[æˆåŠŸ] å·²ä»CSVå¯¼å…¥ {count} æ¡è®°å½•")
    
    def clear_old_cache(self, days: int = 365):
        """æ¸…é™¤è¿‡æœŸçš„ç¼“å­˜æ•°æ®"""
        self.cursor.execute('''
            DELETE FROM annotation_cache
            WHERE created_at < datetime('now', '-' || ? || ' days')
        ''', (days,))
        
        deleted = self.cursor.rowcount
        self.conn.commit()
        
        print(f"[æˆåŠŸ] å·²æ¸…é™¤ {deleted} æ¡è¶…è¿‡{days}å¤©çš„ç¼“å­˜è®°å½•")
    
    def search_metabolite(self, name_pattern: str) -> List[Dict]:
        """
        æŒ‰åç§°æœç´¢ä»£è°¢ç‰©
        
        å‚æ•°:
            name_pattern: åç§°æ¨¡å¼ï¼ˆæ”¯æŒSQL LIKEè¯­æ³•ï¼‰
        
        è¿”å›:
            åŒ¹é…çš„ä»£è°¢ç‰©åˆ—è¡¨
        """
        self.cursor.execute('''
            SELECT DISTINCT metabolite_name, formula, hmdb_id
            FROM annotation_cache
            WHERE metabolite_name LIKE ?
            ORDER BY metabolite_name
        ''', (f'%{name_pattern}%',))
        
        results = []
        for row in self.cursor.fetchall():
            results.append({
                'name': row[0],
                'formula': row[1],
                'hmdb_id': row[2]
            })
        
        return results
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()
            print("[æˆåŠŸ] æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        self.close()


def print_cache_stats():
    """æ‰“å°ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    with MetaboliteCacheDB() as db:
        stats = db.get_stats()
        
        print("\n" + "="*60)
        print("[STATS] ä»£è°¢ç‰©æ³¨é‡Šç¼“å­˜ç»Ÿè®¡")
        print("="*60)
        print(f"  æ€»æŸ¥è¯¢æ¬¡æ•°:     {stats['total_queries']}")
        print(f"  ç¼“å­˜å‘½ä¸­:       {stats['cache_hits']}")
        print(f"  ç¼“å­˜æœªå‘½ä¸­:     {stats['cache_misses']}")
        print(f"  å‘½ä¸­ç‡:         {stats['hit_rate']:.1f}%")
        print(f"  ç¼“å­˜è®°å½•æ€»æ•°:   {stats['total_cached_annotations']}")
        print(f"  æœ€åæ›´æ–°:       {stats['last_updated']}")
        print("="*60 + "\n")


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª æµ‹è¯•ä»£è°¢ç‰©ç¼“å­˜æ•°æ®åº“...")
    
    with MetaboliteCacheDB() as db:
        # æµ‹è¯•æ·»åŠ æ³¨é‡Š
        test_annotation = {
            'name': 'Oleic acid',
            'formula': 'C18H34O2',
            'hmdb_id': 'HMDB0000207',
            'theoretical_mz': 283.2640,
            'error_ppm': 1.23,
            'error_da': 0.0005,
            'source': 'Local'
        }
        
        db.add_annotation(283.2635, 10.0, 'negative', test_annotation)
        print("[æˆåŠŸ] æ·»åŠ æµ‹è¯•æ³¨é‡Š")
        
        # æµ‹è¯•æŸ¥è¯¢
        results = db.query_cache(283.2635, 10.0, 'negative')
        print(f"[æˆåŠŸ] æŸ¥è¯¢ç»“æœ: æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…")
        
        for result in results:
            print(f"   â€¢ {result['name']}: {result['theoretical_mz']:.4f} "
                  f"({result['error_ppm']:.2f} ppm)")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        stats = db.get_stats()
        print(f"\n[STATS] ç¼“å­˜ç»Ÿè®¡:")
        print(f"   æ€»è®°å½•æ•°: {stats['total_cached_annotations']}")
        print(f"   æŸ¥è¯¢æ¬¡æ•°: {stats['total_queries']}")
        print(f"   å‘½ä¸­ç‡: {stats['hit_rate']:.1f}%")

