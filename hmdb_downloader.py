#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HMDBæ•°æ®åº“ä¸‹è½½å’Œå¤„ç†å·¥å…·
è‡ªåŠ¨ä¸‹è½½ã€è§£æå¹¶å¯¼å…¥å®Œæ•´çš„HMDBä»£è°¢ç‰©æ•°æ®åº“
"""

import os
import sys
import requests
import zipfile
import gzip
import xml.etree.ElementTree as ET
from pathlib import Path
import pandas as pd
from tqdm import tqdm
import time


class HMDBDownloader:
    """HMDBæ•°æ®åº“ä¸‹è½½å™¨"""
    
    def __init__(self):
        self.base_dir = Path(__file__).parent
        self.download_dir = self.base_dir / "hmdb_downloads"
        self.download_dir.mkdir(exist_ok=True)
        
        # HMDBä¸‹è½½é“¾æ¥
        self.hmdb_urls = {
            'metabolites_xml': 'https://hmdb.ca/system/downloads/current/hmdb_metabolites.zip',
            'proteins_xml': 'https://hmdb.ca/system/downloads/current/hmdb_proteins.zip',
        }
        
        # æ–‡ä»¶è·¯å¾„
        self.xml_file = None
        self.csv_file = self.base_dir / "hmdb_metabolites.csv"
        
        print("=" * 70)
        print("ğŸ”¬ HMDBæ•°æ®åº“ä¸‹è½½å’Œå¤„ç†å·¥å…·")
        print("=" * 70)
        print(f"\nğŸ“‚ å·¥ä½œç›®å½•: {self.base_dir}")
        print(f"[RECEIVE] ä¸‹è½½ç›®å½•: {self.download_dir}")
        print()
    
    def download_file(self, url: str, filename: str) -> Path:
        """ä¸‹è½½æ–‡ä»¶ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰"""
        filepath = self.download_dir / filename
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè¯¢é—®æ˜¯å¦é‡æ–°ä¸‹è½½
        if filepath.exists():
            print(f"\n[FOLDER] æ–‡ä»¶å·²å­˜åœ¨: {filename}")
            size_mb = filepath.stat().st_size / 1024 / 1024
            print(f"   å¤§å°: {size_mb:.1f} MB")
            
            response = input("   æ˜¯å¦é‡æ–°ä¸‹è½½? (y/N): ").strip().lower()
            if response != 'y':
                print("   [æˆåŠŸ] ä½¿ç”¨ç°æœ‰æ–‡ä»¶")
                return filepath
            print("   ğŸ”„ é‡æ–°ä¸‹è½½...")
        
        print(f"\n[RECEIVE] ä¸‹è½½: {filename}")
        print(f"   URL: {url}")
        
        try:
            # å‘é€è¯·æ±‚
            response = requests.get(url, stream=True, timeout=30)
            response.raise_for_status()
            
            # è·å–æ–‡ä»¶å¤§å°
            total_size = int(response.headers.get('content-length', 0))
            
            # ä¸‹è½½è¿›åº¦æ¡
            with open(filepath, 'wb') as f, tqdm(
                desc=f"   ä¸‹è½½è¿›åº¦",
                total=total_size,
                unit='iB',
                unit_scale=True,
                unit_divisor=1024,
            ) as pbar:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        pbar.update(len(chunk))
            
            size_mb = filepath.stat().st_size / 1024 / 1024
            print(f"   [æˆåŠŸ] ä¸‹è½½å®Œæˆ: {size_mb:.1f} MB")
            return filepath
            
        except Exception as e:
            print(f"   [é”™è¯¯] ä¸‹è½½å¤±è´¥: {e}")
            if filepath.exists():
                filepath.unlink()
            raise
    
    def extract_zip(self, zip_path: Path) -> Path:
        """è§£å‹ZIPæ–‡ä»¶"""
        print(f"\n[ä¿¡æ¯] è§£å‹: {zip_path.name}")
        
        extract_dir = zip_path.parent / zip_path.stem
        extract_dir.mkdir(exist_ok=True)
        
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                # è·å–æ–‡ä»¶åˆ—è¡¨
                files = zip_ref.namelist()
                print(f"   åŒ…å« {len(files)} ä¸ªæ–‡ä»¶")
                
                # è§£å‹
                for file in tqdm(files, desc="   è§£å‹è¿›åº¦"):
                    zip_ref.extract(file, extract_dir)
                
                # æŸ¥æ‰¾XMLæ–‡ä»¶
                xml_files = list(extract_dir.glob("**/*.xml"))
                if xml_files:
                    xml_file = xml_files[0]
                    size_mb = xml_file.stat().st_size / 1024 / 1024
                    print(f"   [æˆåŠŸ] è§£å‹å®Œæˆ")
                    print(f"   [FILE] XMLæ–‡ä»¶: {xml_file.name} ({size_mb:.1f} MB)")
                    return xml_file
                else:
                    raise FileNotFoundError("æœªæ‰¾åˆ°XMLæ–‡ä»¶")
                    
        except Exception as e:
            print(f"   [é”™è¯¯] è§£å‹å¤±è´¥: {e}")
            raise
    
    def parse_xml_to_csv(self, xml_path: Path, max_records: int = None) -> Path:
        """è§£æXMLå¹¶è½¬æ¢ä¸ºCSV"""
        print(f"\nğŸ”„ è§£æXMLæ–‡ä»¶...")
        print(f"   æ–‡ä»¶: {xml_path.name}")
        
        try:
            # è§£æXML
            print("   ğŸ“– è¯»å–XML...")
            tree = ET.parse(xml_path)
            root = tree.getroot()
            
            # XMLå‘½åç©ºé—´
            ns = {'hmdb': 'http://www.hmdb.ca'}
            
            # è·å–æ‰€æœ‰ä»£è°¢ç‰©
            metabolites = root.findall('.//hmdb:metabolite', ns)
            total_count = len(metabolites)
            
            if max_records:
                metabolites = metabolites[:max_records]
                print(f"   [è­¦å‘Š] é™åˆ¶å¤„ç†æ•°é‡: {max_records}/{total_count}")
            else:
                print(f"   [STATS] æ‰¾åˆ° {total_count} ä¸ªä»£è°¢ç‰©")
            
            # è§£ææ•°æ®
            print("   [SEARCH] è§£æä»£è°¢ç‰©ä¿¡æ¯...")
            data = []
            H_MASS = 1.00728  # H+è´¨é‡
            
            for metabolite in tqdm(metabolites, desc="   è§£æè¿›åº¦"):
                try:
                    # åŸºæœ¬ä¿¡æ¯
                    name = metabolite.findtext('hmdb:name', default='Unknown', namespaces=ns)
                    hmdb_id = metabolite.findtext('hmdb:accession', default='', namespaces=ns)
                    formula = metabolite.findtext('hmdb:chemical_formula', default='', namespaces=ns)
                    
                    # CASå·
                    cas_number = metabolite.findtext('hmdb:cas_registry_number', default='', namespaces=ns)
                    
                    # KEGG ID
                    kegg_id = metabolite.findtext('hmdb:kegg_id', default='', namespaces=ns)
                    
                    # ç‰©è´¨åˆ†ç±»ä¿¡æ¯
                    taxonomy = metabolite.find('hmdb:taxonomy', namespaces=ns)
                    kingdom = ''
                    super_class = ''
                    main_class = ''
                    sub_class = ''
                    
                    if taxonomy is not None:
                        kingdom = taxonomy.findtext('hmdb:kingdom', default='', namespaces=ns)
                        super_class = taxonomy.findtext('hmdb:super_class', default='', namespaces=ns)
                        main_class = taxonomy.findtext('hmdb:class', default='', namespaces=ns)
                        sub_class = taxonomy.findtext('hmdb:sub_class', default='', namespaces=ns)
                    
                    # è·å–å•ä¸€åŒä½ç´ è´¨é‡
                    mass_text = metabolite.findtext('hmdb:monisotopic_molecular_weight', 
                                                    default=None, namespaces=ns)
                    
                    if not mass_text:
                        # å°è¯•å…¶ä»–è´¨é‡å­—æ®µ
                        mass_text = metabolite.findtext('hmdb:average_molecular_weight',
                                                       default=None, namespaces=ns)
                    
                    if mass_text:
                        try:
                            neutral_mass = float(mass_text)
                            
                            # è®¡ç®—ç¦»å­åŒ–åçš„m/z
                            mz_positive = neutral_mass + H_MASS  # [M+H]+
                            mz_negative = neutral_mass - H_MASS  # [M-H]-
                            
                            data.append({
                                'name': name,
                                'hmdb_id': hmdb_id,
                                'formula': formula,
                                'molecular_weight': neutral_mass,
                                'cas_number': cas_number,
                                'kegg_id': kegg_id,
                                'kingdom': kingdom,
                                'super_class': super_class,
                                'class': main_class,
                                'sub_class': sub_class,
                                'mz_positive': mz_positive,
                                'mz_negative': mz_negative
                            })
                        except ValueError:
                            continue
                
                except Exception as e:
                    # è·³è¿‡æœ‰é—®é¢˜çš„æ¡ç›®
                    continue
            
            # åˆ›å»ºDataFrame
            print(f"\n   [æˆåŠŸ] æˆåŠŸè§£æ {len(data)} ä¸ªä»£è°¢ç‰©")
            df = pd.DataFrame(data)
            
            # ä¿å­˜ä¸ºCSV
            print(f"   [SAVE] ä¿å­˜ä¸ºCSV: {self.csv_file.name}")
            df.to_csv(self.csv_file, index=False)
            
            size_mb = self.csv_file.stat().st_size / 1024 / 1024
            print(f"   [æˆåŠŸ] CSVæ–‡ä»¶å·²ä¿å­˜ ({size_mb:.1f} MB)")
            
            return self.csv_file
            
        except Exception as e:
            print(f"   [é”™è¯¯] è§£æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def import_to_cache_db(self, csv_path: Path):
        """å¯¼å…¥åˆ°ç¼“å­˜æ•°æ®åº“"""
        print(f"\n[SAVE] å¯¼å…¥åˆ°ç¼“å­˜æ•°æ®åº“...")
        
        try:
            from metabolite_cache_db import MetaboliteCacheDB
            
            # è¯»å–CSV
            print("   ğŸ“– è¯»å–CSV...")
            df = pd.read_csv(csv_path)
            total = len(df)
            print(f"   [STATS] å…± {total} æ¡è®°å½•")
            
            # è¿æ¥æ•°æ®åº“
            print("   ğŸ”Œ è¿æ¥æ•°æ®åº“...")
            cache_db = MetaboliteCacheDB()
            
            # æ‰¹é‡å¯¼å…¥
            print("   [RECEIVE] æ‰¹é‡å¯¼å…¥ä¸­...")
            
            # åˆ†ä¸¤æ¬¡å¯¼å…¥ï¼šæ­£ç¦»å­å’Œè´Ÿç¦»å­
            tolerance_ppm = 10
            
            # æ­£ç¦»å­æ¨¡å¼
            print("\n   ğŸ”¹ å¯¼å…¥æ­£ç¦»å­æ¨¡å¼ [M+H]+:")
            for idx, row in tqdm(df.iterrows(), total=total, desc="      è¿›åº¦"):
                try:
                    annotation = {
                        'name': row['name'],
                        'formula': row['formula'],
                        'hmdb_id': row['hmdb_id'],
                        'molecular_weight': row['molecular_weight'],
                        'cas_number': row.get('cas_number', ''),
                        'kegg_id': row.get('kegg_id', ''),
                        'kingdom': row.get('kingdom', ''),
                        'super_class': row.get('super_class', ''),
                        'class': row.get('class', ''),
                        'sub_class': row.get('sub_class', ''),
                        'theoretical_mz': row['mz_positive'],
                        'measured_mz': row['mz_positive'],
                        'error_ppm': 0.0,
                        'error_da': 0.0,
                        'source': 'HMDB'
                    }
                    cache_db.add_annotation(
                        mz=row['mz_positive'],
                        tolerance_ppm=tolerance_ppm,
                        ion_mode='positive',
                        annotation=annotation
                    )
                except Exception as e:
                    continue
            
            # è´Ÿç¦»å­æ¨¡å¼
            print("\n   ğŸ”¸ å¯¼å…¥è´Ÿç¦»å­æ¨¡å¼ [M-H]-:")
            for idx, row in tqdm(df.iterrows(), total=total, desc="      è¿›åº¦"):
                try:
                    annotation = {
                        'name': row['name'],
                        'formula': row['formula'],
                        'hmdb_id': row['hmdb_id'],
                        'molecular_weight': row['molecular_weight'],
                        'cas_number': row.get('cas_number', ''),
                        'kegg_id': row.get('kegg_id', ''),
                        'kingdom': row.get('kingdom', ''),
                        'super_class': row.get('super_class', ''),
                        'class': row.get('class', ''),
                        'sub_class': row.get('sub_class', ''),
                        'theoretical_mz': row['mz_negative'],
                        'measured_mz': row['mz_negative'],
                        'error_ppm': 0.0,
                        'error_da': 0.0,
                        'source': 'HMDB'
                    }
                    cache_db.add_annotation(
                        mz=row['mz_negative'],
                        tolerance_ppm=tolerance_ppm,
                        ion_mode='negative',
                        annotation=annotation
                    )
                except Exception as e:
                    continue
            
            # æ˜¾ç¤ºç»Ÿè®¡
            stats = cache_db.get_stats()
            print(f"\n   [æˆåŠŸ] å¯¼å…¥å®Œæˆï¼")
            print(f"\n   [STATS] æ•°æ®åº“ç»Ÿè®¡:")
            print(f"      ç¼“å­˜è®°å½•æ€»æ•°: {stats['total_cached_annotations']}")
            
            cache_db.close()
            
        except Exception as e:
            print(f"   [é”™è¯¯] å¯¼å…¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def run(self, skip_download=False, max_records=None):
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        try:
            print("\n" + "â”" * 70)
            print("[LAUNCH] å¼€å§‹ä¸‹è½½å’Œå¤„ç†HMDBæ•°æ®åº“")
            print("â”" * 70)
            
            if not skip_download:
                # 1. ä¸‹è½½
                print("\n[RECEIVE] æ­¥éª¤1/4: ä¸‹è½½HMDBæ•°æ®åº“")
                print("   [TIMER]  é¢„è®¡æ—¶é—´: 5-15åˆ†é’Ÿï¼ˆå–å†³äºç½‘ç»œé€Ÿåº¦ï¼‰")
                
                zip_path = self.download_file(
                    self.hmdb_urls['metabolites_xml'],
                    'hmdb_metabolites.zip'
                )
                
                # 2. è§£å‹
                print("\n[ä¿¡æ¯] æ­¥éª¤2/4: è§£å‹æ–‡ä»¶")
                print("   [TIMER]  é¢„è®¡æ—¶é—´: 2-5åˆ†é’Ÿ")
                
                self.xml_file = self.extract_zip(zip_path)
            else:
                # æŸ¥æ‰¾å·²æœ‰çš„XMLæ–‡ä»¶
                xml_files = list(self.download_dir.glob("**/*.xml"))
                if xml_files:
                    self.xml_file = xml_files[0]
                    print(f"\n[æˆåŠŸ] ä½¿ç”¨ç°æœ‰XMLæ–‡ä»¶: {self.xml_file}")
                else:
                    raise FileNotFoundError("æœªæ‰¾åˆ°XMLæ–‡ä»¶ï¼Œè¯·å…ˆä¸‹è½½")
            
            # 3. è§£æ
            print("\nğŸ”„ æ­¥éª¤3/4: è§£æXMLå¹¶è½¬æ¢ä¸ºCSV")
            print("   [TIMER]  é¢„è®¡æ—¶é—´: 5-10åˆ†é’Ÿ")
            
            csv_path = self.parse_xml_to_csv(self.xml_file, max_records)
            
            # 4. å¯¼å…¥æ•°æ®åº“
            print("\n[SAVE] æ­¥éª¤4/4: å¯¼å…¥åˆ°ç¼“å­˜æ•°æ®åº“")
            print("   [TIMER]  é¢„è®¡æ—¶é—´: 10-20åˆ†é’Ÿ")
            
            self.import_to_cache_db(csv_path)
            
            # å®Œæˆ
            print("\n" + "=" * 70)
            print("[CELEBRATE] HMDBæ•°æ®åº“ä¸‹è½½å’Œå¯¼å…¥å®Œæˆï¼")
            print("=" * 70)
            
            # ç»Ÿè®¡ä¿¡æ¯
            df = pd.read_csv(csv_path)
            print(f"\n[STATS] æ•°æ®åº“ç»Ÿè®¡:")
            print(f"   ä»£è°¢ç‰©æ€»æ•°: {len(df):,}")
            print(f"   CSVæ–‡ä»¶: {csv_path}")
            print(f"   ç¼“å­˜æ•°æ®åº“: {self.base_dir / 'metabolite_cache.db'}")
            
            print(f"\n[æˆåŠŸ] ç°åœ¨å¯ä»¥åœ¨GUIä¸­ä½¿ç”¨å®Œæ•´çš„HMDBæ•°æ®åº“äº†ï¼")
            print(f"\nğŸ§ª æµ‹è¯•æ–¹æ³•:")
            print(f"   1. è¿è¡Œ: python3 test_mz_187.py")
            print(f"   2. åœ¨GUIä¸­ï¼šå³é”®ç¦»å­è¡¨ â†’ ä»£è°¢ç‰©æŸ¥è¯¢")
            print(f"   3. å¯¼å‡ºæ—¶é€‰æ‹©ï¼šåŒ…å«ä»£è°¢ç‰©æ³¨é‡Š")
            
            return True
            
        except KeyboardInterrupt:
            print("\n\n[è­¦å‘Š] ç”¨æˆ·ä¸­æ–­")
            return False
        except Exception as e:
            print(f"\n\n[é”™è¯¯] å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='HMDBæ•°æ®åº“ä¸‹è½½å’Œå¤„ç†å·¥å…·')
    parser.add_argument('--skip-download', action='store_true',
                       help='è·³è¿‡ä¸‹è½½æ­¥éª¤ï¼ˆä½¿ç”¨å·²æœ‰æ–‡ä»¶ï¼‰')
    parser.add_argument('--max-records', type=int, default=None,
                       help='é™åˆ¶å¤„ç†çš„è®°å½•æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰')
    
    args = parser.parse_args()
    
    # è¿è¡Œ
    downloader = HMDBDownloader()
    success = downloader.run(
        skip_download=args.skip_download,
        max_records=args.max_records
    )
    
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()

